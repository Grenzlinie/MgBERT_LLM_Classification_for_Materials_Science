{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from MatSciBERT.normalize_text import normalize\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "## 设置随机数种子\n",
    "setup_seed(42)\n",
    "\n",
    "config = AutoConfig.from_pretrained('./MatSciBERT')\n",
    "config.max_position_embeddings = 900\n",
    "bert_model = AutoModel.from_pretrained('./MatSciBERT', config=config, ignore_mismatched_sizes=True)\n",
    "\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        outputs = self.bert(input_ids=input_id, attention_mask=mask,return_dict=True, output_attentions=True)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        attentions = outputs.attentions\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer, attentions\n",
    "\n",
    "\n",
    "## 数据获取\n",
    "tokenizer = AutoTokenizer.from_pretrained('./MatSciBERT')\n",
    "def find_text(composition):\n",
    "    file_path = os.path.join('../description/', composition + '.txt')\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "df = pd.read_csv('../unique_compositions.csv')\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "## 模型读取\n",
    "from torch.serialization import load\n",
    "model_path = 'MgBERT.pth'\n",
    "model_data = torch.load(model_path, map_location=device)\n",
    "model = BertClassifier()\n",
    "model.to(device)\n",
    "model.load_state_dict(model_data)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmg_text = find_text('Cu55Zr42.5Ga2.5')\n",
    "ribbon_text = find_text('Ag20Al25La55')\n",
    "nr_text = find_text('Al40Mn25Si35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bmg_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 分析输入输出关系\n",
    "from lime import lime_text\n",
    "import math\n",
    "def get_prob(input_text):\n",
    "    with torch.no_grad():\n",
    "        if isinstance(input_text, str):\n",
    "            input_text = [input_text]\n",
    "        len_input = len(input_text)\n",
    "        batch_size = 20\n",
    "        batch_num = math.ceil(len_input/batch_size)\n",
    "        whole_output = []\n",
    "        for i in range(batch_num):\n",
    "            segment_start = i * batch_size\n",
    "            segment_end = (i + 1) * batch_size if (i + 1) * batch_size < len_input else len_input\n",
    "            segment_input_text = input_text[segment_start:segment_end]\n",
    "            inputs = tokenizer([normalize(text) for text in segment_input_text],\n",
    "                                padding='max_length', \n",
    "                                max_length=900, \n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\").to(device)\n",
    "            output, attention = model(inputs['input_ids'], inputs['attention_mask'])\n",
    "            whole_output.append(output)\n",
    "        op = torch.softmax(torch.cat(whole_output, dim=0), dim=1).cpu().numpy()\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_prob(bmg_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_prob(ribbon_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_prob(nr_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "class_names = ['BMG', 'Ribbon', 'NR']\n",
    "explainer = LimeTextExplainer(class_names=class_names, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_list = []\n",
    "for i in range(3):\n",
    "    if i == 0 :\n",
    "        input_text = bmg_text\n",
    "        exp = explainer.explain_instance(input_text, get_prob, num_features=50, num_samples=1000, labels=[0])\n",
    "        store_list.append(exp.as_list(label=0))\n",
    "        print ('Explanation for class %s' % class_names[0])\n",
    "        print ('\\n'.join(map(str, exp.as_list(label=0))))\n",
    "        print ()\n",
    "    elif i == 1 :\n",
    "        input_text = ribbon_text\n",
    "        exp = explainer.explain_instance(input_text, get_prob, num_features=50, num_samples=1000, labels=[1])\n",
    "        store_list.append(exp.as_list(label=1))\n",
    "        print ('Explanation for class %s' % class_names[1])\n",
    "        print ('\\n'.join(map(str, exp.as_list(label=1))))\n",
    "        print()\n",
    "    else:\n",
    "        input_text = nr_text\n",
    "        exp = explainer.explain_instance(input_text, get_prob, num_features=50, num_samples=1000, labels=[2])\n",
    "        store_list.append(exp.as_list(label=2))\n",
    "        print ('Explanation for class %s' % class_names[2])\n",
    "        print ('\\n'.join(map(str, exp.as_list(label=2))))\n",
    "        print()\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(store_list)\n",
    "df.to_excel(\"lime_output_list.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('lime_output_list.xlsx').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmg_data = df[0].tolist()\n",
    "bmg_data = [eval(i) for i in bmg_data]\n",
    "ribbon_data = df[1].tolist()\n",
    "ribbon_data = [eval(i) for i in ribbon_data]\n",
    "nr_data = df[2].tolist()\n",
    "nr_data = [eval(i) for i in nr_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmg_label = [i[0] for i in bmg_data]\n",
    "bmg_value = [i[1] for i in bmg_data]\n",
    "ribbon_label = [i[0] for i in ribbon_data]\n",
    "ribbon_value = [i[1] for i in ribbon_data]\n",
    "nr_label = [i[0] for i in nr_data]\n",
    "nr_value = [i[1] for i in nr_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Assuming you have a list of 50 labels and 50 float values\n",
    "labels = bmg_label[1:25]\n",
    "values = bmg_value[1:25]\n",
    "\n",
    "fontsize = 18\n",
    "\n",
    "# Set up the angle for each bar\n",
    "num_vars = len(labels)\n",
    "angles = np.linspace(0, 2*np.pi, num_vars, endpoint=False).tolist()\n",
    "print(angles)\n",
    "# The plot is made circular by appending the start value to the end.\n",
    "values = np.concatenate((values,[values[0]]))\n",
    "angles += angles[:1]\n",
    "\n",
    "# Create a polar subplot\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "# bar width\n",
    "bar_width = 2 * np.pi / num_vars * 0.8\n",
    "\n",
    "# Draw the bars\n",
    "ax.bar(angles, values, color='#a3bded', linewidth=2, width=bar_width)\n",
    "\n",
    "# Set the direction of the zero angle\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "# Set the labels for each bar\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(labels, fontsize=fontsize, fontweight='bold')\n",
    "ax.tick_params(axis='y', labelsize=fontsize, rotation=-18)\n",
    "\n",
    "\n",
    "# To make the labels readable, set the alignment and rotation\n",
    "for label, angle in zip(ax.get_xticklabels(), angles):\n",
    "    if angle in (0, np.pi):\n",
    "        label.set_horizontalalignment('center')\n",
    "    elif 0 < angle < np.pi:\n",
    "        label.set_horizontalalignment('left')\n",
    "    else:\n",
    "        label.set_horizontalalignment('right')\n",
    "\n",
    "# Fine-tune the grid and other elements if needed\n",
    "ax.xaxis.grid(True, color='grey', linestyle='--', linewidth=1)\n",
    "ax.yaxis.grid(True, color='grey', linestyle='--', linewidth=1)\n",
    "# Show the plot\n",
    "plt.savefig('bmg_lime.svg', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Assuming you have a list of 50 labels and 50 float values\n",
    "labels = ribbon_label[:25]\n",
    "values = ribbon_value[:25]\n",
    "\n",
    "fontsize = 18\n",
    "\n",
    "# Set up the angle for each bar\n",
    "num_vars = len(labels)\n",
    "angles = np.linspace(0, 2*np.pi, num_vars, endpoint=False).tolist()\n",
    "print(angles)\n",
    "# The plot is made circular by appending the start value to the end.\n",
    "values = np.concatenate((values,[values[0]]))\n",
    "angles += angles[:1]\n",
    "\n",
    "# Create a polar subplot\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "# bar width\n",
    "bar_width = 2 * np.pi / num_vars * 0.8\n",
    "\n",
    "# Draw the bars\n",
    "ax.bar(angles, values, color='#fcb69f', linewidth=2, width=bar_width)\n",
    "\n",
    "# Set the direction of the zero angle\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "# Set the labels for each bar\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(labels, fontsize=fontsize, fontweight='bold')\n",
    "ax.tick_params(axis='y', labelsize=fontsize, rotation=-18)\n",
    "\n",
    "\n",
    "# To make the labels readable, set the alignment and rotation\n",
    "for label, angle in zip(ax.get_xticklabels(), angles):\n",
    "    if angle in (0, np.pi):\n",
    "        label.set_horizontalalignment('center')\n",
    "    elif 0 < angle < np.pi:\n",
    "        label.set_horizontalalignment('left')\n",
    "    else:\n",
    "        label.set_horizontalalignment('right')\n",
    "\n",
    "\n",
    "# Fine-tune the grid and other elements if needed\n",
    "ax.xaxis.grid(True, color='grey', linestyle='--', linewidth=1)\n",
    "ax.yaxis.grid(True, color='grey', linestyle='--', linewidth=1)\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig('ribbon_lime.svg', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Assuming you have a list of 50 labels and 50 float values\n",
    "labels = nr_label[:25]\n",
    "values = nr_value[:25]\n",
    "\n",
    "fontsize = 18\n",
    "\n",
    "# Set up the angle for each bar\n",
    "num_vars = len(labels)\n",
    "angles = np.linspace(0, 2*np.pi, num_vars, endpoint=False).tolist()\n",
    "print(angles)\n",
    "# The plot is made circular by appending the start value to the end.\n",
    "values = np.concatenate((values,[values[0]]))\n",
    "angles += angles[:1]\n",
    "\n",
    "# Create a polar subplot\n",
    "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(polar=True))\n",
    "\n",
    "# bar width\n",
    "bar_width = 2 * np.pi / num_vars * 0.8\n",
    "\n",
    "# Draw the bars\n",
    "ax.bar(angles, values, color='#43e97b', linewidth=2, width=bar_width)\n",
    "\n",
    "# Set the direction of the zero angle\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "# Set the labels for each bar\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(labels, fontsize=fontsize, fontweight='bold')\n",
    "ax.tick_params(axis='y', labelsize=fontsize, rotation=-18)\n",
    "\n",
    "\n",
    "# To make the labels readable, set the alignment and rotation\n",
    "for label, angle in zip(ax.get_xticklabels(), angles):\n",
    "    if angle in (0, np.pi):\n",
    "        label.set_horizontalalignment('center')\n",
    "    elif 0 < angle < np.pi:\n",
    "        label.set_horizontalalignment('left')\n",
    "    else:\n",
    "        label.set_horizontalalignment('right')\n",
    "\n",
    "# Fine-tune the grid and other elements if needed\n",
    "ax.xaxis.grid(True, color='grey', linestyle='--', linewidth=1)\n",
    "ax.yaxis.grid(True, color='grey', linestyle='--', linewidth=1)\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig('nr_lime.svg', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     for test_input, test_label in data_loader:\n",
    "#         # 如果有GPU，则使用GPU，接下来的操作同训练\n",
    "#         # test_label = test_label.to(device)\n",
    "#         # token_type_ids = test_input['token_type_ids'].to(device)\n",
    "#         # attention_mask = test_input['attention_mask'].to(device)\n",
    "#         # input_ids = test_input['input_ids'].squeeze(1).to(device)\n",
    "#         # Cu20Hf65Ni15.txt\n",
    "#         input_text = \"Composition Information: [Cu20Hf65Ni15 consists of 20% Copper, 65% Hafnium, and 15% Nickel].\"\n",
    "#         inputs = tokenizer(normalize(input_text),\n",
    "#                                 padding='max_length', \n",
    "#                                 max_length = 900, \n",
    "#                                 truncation=True,\n",
    "#                                 return_tensors=\"pt\").to(device)\n",
    "#         output, attention = model(inputs['input_ids'], inputs['attention_mask'])\n",
    "#         # output, attention = model(input_ids, attention_mask)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention全局可视化\n",
    "# should combine with model loading\n",
    "# from bertviz import head_view, model_view\n",
    "# tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0].tolist())\n",
    "# # tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "# a = model_view(attention, tokens, html_action='return')\n",
    "# b = head_view(attention, tokens, html_action='return')\n",
    "# with open('short_model_view.html', 'w') as file:\n",
    "#     file.write(a.data)\n",
    "\n",
    "# with open('short_head_view.html', 'w') as file:\n",
    "#     file.write(b.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## last layer attention可视化\n",
    "inputs = tokenizer(normalize(nr_text),\n",
    "                                padding='max_length', \n",
    "                                max_length = 900, \n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\").to(device)\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0].tolist())\n",
    "output, attention = model(inputs['input_ids'], inputs['attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokens)\n",
    "print(len(tokens))\n",
    "p1 = [i for i, token in enumerate(tokens) if token == 'element']\n",
    "p2 = [i for i, token in enumerate(tokens) if token == 'alloy']\n",
    "p3 = [i for i, token in enumerate(tokens) if token == '[SEP]']\n",
    "print(p1)\n",
    "print(p2)\n",
    "print(p3)\n",
    "print(tokens[31:33])\n",
    "print(tokens[316:318])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_attention = attention[-1]  # Extracting the last layer attention score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_last_layer_attention = last_layer_attention.mean(dim=1).squeeze(0)\n",
    "print(mean_last_layer_attention.shape)\n",
    "print(mean_last_layer_attention)\n",
    "cls_attention = mean_last_layer_attention[0]\n",
    "print(cls_attention.shape)\n",
    "print(cls_attention.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_layer = cls_attention[:31].sum()\n",
    "elem_layer = cls_attention[31:316].sum()\n",
    "alloy_layer = cls_attention[316:370].sum()\n",
    "print(comp_layer, elem_layer, alloy_layer)\n",
    "c_e = comp_layer / (31/370)\n",
    "e_e = elem_layer / ((316-31)/370)\n",
    "a_e = alloy_layer / ((370-316)/370)\n",
    "print(c_e, e_e, a_e)\n",
    "ce_percentage = c_e / (c_e + e_e + a_e)\n",
    "ee_percentage = e_e / (c_e + e_e + a_e)\n",
    "ae_percentage = a_e / (c_e + e_e + a_e)\n",
    "print(ce_percentage, ee_percentage, ae_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_excel('confusion_matrix——5577.xlsx', usecols=lambda x: x != 'Unnamed: 0')\n",
    "row_names = ['r_BMG', 'r_Ribbon', 'r_NR']\n",
    "col_names = ['p_BMG', 'p_Ribbon', 'p_NR']\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8, 6))\n",
    "heatmap = sns.heatmap(df, annot=True, cmap='Blues', fmt='g', xticklabels=col_names, yticklabels=row_names,annot_kws={\"fontsize\":14})\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel('Predicted label', fontsize=12)\n",
    "plt.ylabel('True label', fontsize=12)\n",
    "plt.title('Confusion Matrix', fontsize=12)\n",
    "plt.savefig('confusion_matrix_5577.svg', dpi=600)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matscibert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
